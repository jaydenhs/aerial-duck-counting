{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# check if device runs cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from models.unet import UNet\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "# Paths\n",
    "image_dir = \"labelstudio-export/images\"\n",
    "annotations_path = \"labelstudio-export/annotations.json\"\n",
    "output_dir = \"labelstudio-export/annotated-images\"\n",
    "\n",
    "# Parameters\n",
    "min_annotations = 200  # Minimum annotations threshold\n",
    "sigma = 5  # For Gaussian blur\n",
    "\n",
    "# Load annotations\n",
    "with open(annotations_path, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Define a color map for different keypoint labels\n",
    "class_to_idx = {\n",
    "    'Adult Male': 0,\n",
    "    'Adult Female': 1,\n",
    "    'Juvenile': 2\n",
    "}\n",
    "\n",
    "# Gaussian kernel to generate density maps\n",
    "def generate_density_map(height, width, points, sigma=10):\n",
    "    density_map = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "    for point in points:\n",
    "        x = int(point['x'] * width / 100)\n",
    "        y = int(point['y'] * height / 100)\n",
    "        if 0 <= x < width and 0 <= y < height:\n",
    "            density_map[y, x] += 1\n",
    "            \n",
    "    return gaussian_filter(density_map, sigma=sigma)\n",
    "\n",
    "# Dataset\n",
    "class EiderDuckDataset(Dataset):\n",
    "    def __init__(self, annotations, image_dir, transform=None):\n",
    "        self.annotations = annotations\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.filtered_annotations = self.filter_annotations()\n",
    "\n",
    "    def filter_annotations(self):\n",
    "        filtered = []\n",
    "        for annotation in self.annotations:\n",
    "            valid_annotations = [ann for ann in annotation['annotations'] if not ann['was_cancelled']]\n",
    "            if valid_annotations and len(valid_annotations[0]['result']) >= min_annotations:\n",
    "                filtered.append(annotation)\n",
    "        return filtered\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filtered_annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.filtered_annotations[idx]\n",
    "        \n",
    "        # Image\n",
    "        image_file = annotation['file_upload']\n",
    "        image_path = os.path.join(self.image_dir, image_file)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Create density maps (one per class)\n",
    "        density_maps = np.zeros((3, 1024, 1024), dtype=np.float32)\n",
    "        points = {'Adult Male': [], 'Adult Female': [], 'Juvenile': []}\n",
    "        \n",
    "        # Extract annotations\n",
    "        for result in annotation['annotations'][0]['result']:\n",
    "            if result['type'] == 'keypointlabels':\n",
    "                label = result['value']['keypointlabels'][0]\n",
    "                if label in class_to_idx:\n",
    "                    points[label].append({'x': result['value']['x'], 'y': result['value']['y']})\n",
    "        \n",
    "        # Generate density maps for each class\n",
    "        for label, point_list in points.items():\n",
    "            # Check if the label exists in the mapping\n",
    "            class_idx = class_to_idx[label]\n",
    "            density_maps[class_idx] = generate_density_map(1024, 1024, point_list, sigma=sigma)\n",
    "\n",
    "        # Transform image and density maps to tensors\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        density_maps = torch.from_numpy(density_maps)\n",
    "\n",
    "        return image, density_maps\n",
    "\n",
    "# Loss function (masked loss)\n",
    "def masked_mse_loss(pred, target, mask):\n",
    "    loss = ((pred - target) ** 2) * mask\n",
    "    return loss.sum() / mask.sum()\n",
    "\n",
    "# Training loop with tqdm for progress tracking\n",
    "def train_model(model, dataloader, num_epochs=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_iterator = tqdm(dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")  # Progress bar for batches\n",
    "\n",
    "        for images, density_maps in epoch_iterator:\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Apply mask where density map > 0 (where annotations exist)\n",
    "            mask = (density_maps > 0).float()\n",
    "\n",
    "            loss = masked_mse_loss(outputs, density_maps, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update tqdm description with current loss\n",
    "            epoch_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "        # Print density maps at the end of the epoch\n",
    "        with torch.no_grad():\n",
    "            plot_sample(images, density_maps, outputs, epoch)\n",
    "\n",
    "def plot_sample(images, density_maps, outputs, epoch):\n",
    "    # Move tensors to CPU for visualization\n",
    "    images = images.cpu().numpy()\n",
    "    density_maps = density_maps.cpu().numpy()\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "\n",
    "    print(f\"outputs: [{outputs.min()}, {outputs.max()}]\")\n",
    "    print(f\"density_maps: [{density_maps.min()}, {density_maps.max()}]\")\n",
    "    \n",
    "    # Normalize outputs and density maps for visualization\n",
    "    outputs = (outputs - outputs.min()) / (outputs.max() - outputs.min())\n",
    "    density_maps = (density_maps - density_maps.min()) / (density_maps.max() - density_maps.min())\n",
    "\n",
    "    # Plot the images and corresponding density maps\n",
    "    max_samples = 1\n",
    "    num_samples = min(images.shape[0], max_samples)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Plot Input Image\n",
    "        plt.subplot(num_samples * 2, 5, i * 5 + 1)\n",
    "        plt.imshow(images[i].transpose(1, 2, 0))  # Convert to HWC format\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Visualizing combined Ground Truth Density Map\n",
    "        plt.subplot(num_samples * 2, 5, i * 5 + 2)\n",
    "        plt.imshow(density_maps[i].transpose(1, 2, 0))  # Convert to HWC format\n",
    "        plt.title(\"GT Density Map\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plotting each channel for the Ground Truth Density Map\n",
    "        for c in range(3):  # Assuming 3 channels: R, G, B\n",
    "            plt.subplot(num_samples * 2, 5, i * 5 + 3 + c)\n",
    "            plt.imshow(density_maps[i][c], cmap='jet')  # Use a color map for visualization\n",
    "            plt.title(f\"Channel {c+1} ({list(class_to_idx.keys())[c]})\") # Channel index starts from 1\n",
    "            plt.axis('off')\n",
    "\n",
    "        # Visualizing combined Predicted Density Map\n",
    "        plt.subplot(num_samples * 2, 5, i * 5 + 7)\n",
    "        plt.imshow(outputs[i].transpose(1, 2, 0))  # Convert to HWC format\n",
    "        plt.title(\"Pred Density Map\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plotting each channel for the Predicted Density Map\n",
    "        for c in range(3):  # Assuming 3 channels: R, G, B\n",
    "            plt.subplot(num_samples * 2, 5, i * 5 + 8 + c)\n",
    "            plt.imshow(outputs[i][c], cmap='jet')  # Use a color map for visualization\n",
    "            plt.title(f\"Channel {c+1} ({list(class_to_idx.keys())[c]})\")  # Channel index starts from 1\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create dataset and dataloader with resizing\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((1024, 1024)),  # Resize all images to 256x256\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = EiderDuckDataset(annotations, image_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Initialize model, move to GPU if available\n",
    "model = UNet(in_channels=3, num_classes=3).to(device)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-duck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
